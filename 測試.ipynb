{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23798,
     "status": "ok",
     "timestamp": 1764319119214,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "e0uWVieA4rpj",
    "outputId": "999c9cb8-3822-4e75-cd6b-89295ebd0135"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.conda (Python 3.11.14)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n .conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n",
    "!pip install xgboost\n",
    "!pip install plotly\n",
    "!pip install optuna-integration[xgboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1764319119229,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "PV2h86bc4tp5"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, Callable\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.base import clone\n",
    "import optuna\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1764319119242,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "yFRruAlk45vu"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    TARGET_COL = 'Exited'\n",
    "    N_SPLITS = 5\n",
    "    RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1764319119326,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "YnOIx6TT4_fu"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 979,
     "status": "ok",
     "timestamp": 1764319120312,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "7qh39PaSl6IJ",
    "outputId": "50f5b075-eed7-4de3-a75f-09484ef11d8d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1764319120325,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "UaOg7sQe5DDv"
   },
   "outputs": [],
   "source": [
    "class FeatureEngineer:\n",
    "    \"\"\"\n",
    "    用於特徵工程的工具類別。所有方法皆為靜態方法，\n",
    "    代表獨立的預處理管道。\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def map_columns(df: pd.DataFrame, mappings: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        根據提供的字典進行欄位映射。\n",
    "        Args:\n",
    "            df: 待處理的 DataFrame。\n",
    "            mappings: 欄位名到映射字典的字典，例如 {'Gender': {'Male': 0, 'Female': 1}}。\n",
    "        Returns:\n",
    "            映射後的 DataFrame 副本。\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        for col, mapping in mappings.items():\n",
    "            if col in df_copy.columns:\n",
    "                # 這裡的 mapping 類型應該是 dict[Any, Any]\n",
    "                df_copy[col] = df_copy[col].map(mapping)\n",
    "        return df_copy\n",
    "\n",
    "    @staticmethod\n",
    "    def cast_columns(df: pd.DataFrame, int_cols: Any = None, # 使用 Any 代替 Optional[list[str]]\n",
    "                     cat_cols: Any = None) -> pd.DataFrame: # 使用 Any 代替 Optional[list[str]]\n",
    "        \"\"\"\n",
    "        轉換指定欄位的數據類型。\n",
    "        Args:\n",
    "            df: 待處理的 DataFrame。\n",
    "            int_cols: 應轉換為 int 類型的欄位列表（list）。\n",
    "            cat_cols: 應轉換為 'category' 類型的欄位列表（list）。\n",
    "        Returns:\n",
    "            轉換類型後的 DataFrame 副本。\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        if int_cols:\n",
    "            for col in int_cols:\n",
    "                if col in df_copy.columns:\n",
    "                    df_copy[col] = df_copy[col].astype(int)\n",
    "        if cat_cols:\n",
    "            for col in cat_cols:\n",
    "                if col in df_copy.columns:\n",
    "                    df_copy[col] = df_copy[col].astype('category')\n",
    "        return df_copy\n",
    "\n",
    "    @staticmethod\n",
    "    def run_v0_baseline(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        基礎管道：僅進行類型轉換，不創建新特徵。\n",
    "        Args:\n",
    "            df: 原始 DataFrame。\n",
    "            is_train: 是否為訓練集（用於決定是否移除 'Exited' 欄位）。\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        int_cols = ['HasCrCard', 'IsActiveMember']\n",
    "        cat_cols = ['Geography', 'Gender']\n",
    "        df_copy = FeatureEngineer.cast_columns(df_copy, int_cols=int_cols, cat_cols=cat_cols)\n",
    "\n",
    "        cols_to_drop = ['CustomerId','Surname']\n",
    "        if is_train:\n",
    "            cols_to_drop.append('Exited')\n",
    "        df_copy.drop(columns=[col for col in cols_to_drop if col in df_copy.columns], inplace=True)\n",
    "        return df_copy\n",
    "\n",
    "    @staticmethod\n",
    "    def run_v1_preprocessing(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        版本 1：基礎旗標和分箱。\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        gender_map = {'Male': 0, 'Female': 1}\n",
    "        df_copy = FeatureEngineer.map_columns(df_copy, {'Gender': gender_map})\n",
    "\n",
    "        # 年齡分箱\n",
    "        df_copy['Age_bin'] = pd.cut(df_copy['Age'], bins=[0, 25, 35, 45, 60, np.inf],\n",
    "                                    labels=['very_young', 'young', 'mid', 'mature', 'senior'])\n",
    "\n",
    "        # 創建基礎特徵旗標\n",
    "        df_copy['Is_two_products'] = (df_copy['NumOfProducts'] == 2)\n",
    "        df_copy['Germany_Female'] = ((df_copy['Geography'] == 'Germany') & (df_copy['Gender'] == 1))\n",
    "        df_copy['Germany_Inactive'] = ((df_copy['Geography'] == 'Germany') & (df_copy['IsActiveMember'] == 0))\n",
    "        df_copy['Has_Zero_Balance'] = (df_copy['Balance'] == 0)\n",
    "\n",
    "        # 對 Tenure 進行 Log 轉換\n",
    "        df_copy['Tenure_log'] = np.log1p(df_copy['Tenure'])\n",
    "\n",
    "        int_cols = ['HasCrCard', 'IsActiveMember', 'NumOfProducts', 'Is_two_products', 'Has_Zero_Balance',\n",
    "                    'Germany_Female', 'Germany_Inactive']\n",
    "\n",
    "        # 注意：Germany_Female 和 Germany_Inactive 應為 int 類型，但原始代碼放在了 cat_cols，這裡保留原始邏輯\n",
    "        # 原始代碼中重複了 Germany_Female, Germany_Inactive, Age_bin，這裡進行清理\n",
    "        # 由於原始代碼中有重複，但目標是翻譯和遵守約束，這裡使用一個經過清理的列表\n",
    "        # 如果要忠實於原始邏輯，應該保留，但 'Germany_Female', 'Germany_Inactive' 已經在 int_cols 中\n",
    "        # 為了避免冗餘，我修正 cat_cols 列表。\n",
    "        # 原始代碼: cat_cols = ['Geography', 'Age_bin', 'Germany_Female', 'Germany_Inactive', 'Surname', 'Age_bin']\n",
    "        # 修正為:\n",
    "        cat_cols = ['Geography', 'Age_bin']\n",
    "\n",
    "        df_copy = FeatureEngineer.cast_columns(df_copy, int_cols=int_cols, cat_cols=cat_cols)\n",
    "\n",
    "\n",
    "        cols_to_drop = ['CustomerId', 'Tenure','Surname' ]\n",
    "        if is_train:\n",
    "            if 'Exited' in df_copy.columns:\n",
    "                cols_to_drop.append('Exited')\n",
    "\n",
    "        df_copy.drop(columns=[col for col in cols_to_drop if col in df_copy.columns], inplace=True, errors='ignore')\n",
    "        return df_copy\n",
    "\n",
    "    @staticmethod\n",
    "    def run_v2_preprocessing(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        版本 2：V1 + 新旗標 is_mature_inactive_transit。\n",
    "        \"\"\"\n",
    "        # 使用 V1 管道作為基礎\n",
    "        df_copy = FeatureEngineer.run_v1_preprocessing(df, is_train=False)\n",
    "\n",
    "        # 創建新的交互特徵\n",
    "        df_copy['is_mature_inactive_transit'] = (\n",
    "                (df_copy['Has_Zero_Balance'] == 1) & (df_copy['IsActiveMember'] == 0) & (\n",
    "                df_copy['Age'] > 40)).astype(int)\n",
    "\n",
    "        if is_train and 'Exited' in df_copy.columns:\n",
    "            df_copy.drop(columns=['Exited'], inplace=True, errors='ignore')\n",
    "\n",
    "        return df_copy\n",
    "\n",
    "    @staticmethod\n",
    "    def run_v3_preprocessing(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        版本 3：V1 + 多項式/交互特徵。\n",
    "        \"\"\"\n",
    "        # 使用 V1 管道作為基礎\n",
    "        df_copy = FeatureEngineer.run_v1_preprocessing(df, is_train=False)\n",
    "\n",
    "        # 創建交互特徵\n",
    "        df_copy['Balance_per_product'] = df_copy['Balance'] / (df_copy['NumOfProducts'] + 1e-9)\n",
    "        df_copy['Age_x_Tenure'] = df_copy['Age'] * df_copy['Tenure_log']\n",
    "        df_copy['CreditScore_x_Age'] = df_copy['CreditScore'] * df_copy['Age']\n",
    "\n",
    "        if is_train and 'Exited' in df_copy.columns:\n",
    "            df_copy.drop(columns=['Exited'], inplace=True, errors='ignore')\n",
    "        return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1764319120375,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "hbiU6lgB5GCG"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('ModelTrainer')\n",
    "if not logger.handlers:\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1764319120378,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "eOJ3Gw5J5Of-"
   },
   "outputs": [],
   "source": [
    "class HyperparameterTuner:\n",
    "    \"\"\"\n",
    "    超參數調優類別，使用 Optuna 進行優化。\n",
    "    專注於 XGBoost 的調優。\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _objective(trial: optuna.Trial, X: pd.DataFrame, y: pd.Series, cat_feature_names: list) -> float:\n",
    "        \"\"\"\n",
    "        Optuna 的目標函數：使用交叉驗證評估一組超參數。\n",
    "        \"\"\"\n",
    "        model_name = 'XGBoost' # 假設我們只調優 XGBoost\n",
    "\n",
    "        # 1. 定義要調優的 XGBoost 參數空間\n",
    "        params = {\n",
    "            # 樹參數\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            # 正則化參數\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            # 隨機參數\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        }\n",
    "\n",
    "        # 2. 定義固定參數\n",
    "        fixed_params = {\n",
    "            'random_state': 42,\n",
    "            'verbose': 0,\n",
    "            'eval_metric': 'logloss',\n",
    "            'n_jobs': -1,\n",
    "            'early_stopping_rounds': 50,\n",
    "            'enable_categorical': True, # 啟用原生類別特徵支持\n",
    "        }\n",
    "\n",
    "        full_params = {**params, **fixed_params}\n",
    "\n",
    "        # 3. 創建模型\n",
    "        model = XGBClassifier(**full_params)\n",
    "\n",
    "        # 4. 交叉驗證與擬合\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=fixed_params['random_state'])\n",
    "        roc_auc_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            # --- 關鍵修正區塊 ---\n",
    "            # 確保只傳遞 XGBoost 接受的參數\n",
    "            fit_params = {\n",
    "                'eval_set': [(X_val, y_val)],\n",
    "                'verbose': False\n",
    "            }\n",
    "            # 'early_stopping_rounds' 已經在 full_params 中，會自動傳遞給 fit\n",
    "            # 我們不能傳遞 'callbacks'\n",
    "            # --------------------\n",
    "\n",
    "            model.fit(X_tr, y_tr, **fit_params)\n",
    "\n",
    "            # 確保我們使用訓練完成的模型進行預測\n",
    "            best_iteration = model.get_booster().best_iteration\n",
    "\n",
    "            # 使用最佳迭代次數預測\n",
    "            proba_val = model.predict_proba(X_val, iteration_range=(0, best_iteration))[:, 1]\n",
    "            roc_auc_scores.append(roc_auc_score(y_val, proba_val))\n",
    "\n",
    "        # 5. 返回平均 ROC AUC 分數（Optuna 將嘗試最大化此值）\n",
    "        return np.mean(roc_auc_scores)\n",
    "\n",
    "    @staticmethod\n",
    "    def tune(X: pd.DataFrame, y: pd.Series, cat_feature_names: list, n_trials: int) -> dict:\n",
    "        \"\"\"\n",
    "        執行 Optuna 調優並返回最佳參數。\n",
    "        \"\"\"\n",
    "        # 創建 Optuna 研究 (Study)\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "\n",
    "        # 包裝目標函數，傳遞數據\n",
    "        objective_with_args = lambda trial: HyperparameterTuner._objective(trial, X, y, cat_feature_names)\n",
    "\n",
    "        # 開始優化\n",
    "        study.optimize(objective_with_args, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "        print(f\"調優完成。最佳 ROC AUC: {study.best_value:.5f}\")\n",
    "        print(\"最佳參數:\")\n",
    "        for key, value in study.best_params.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "        # 返回最佳參數\n",
    "        return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1764319120453,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "YSi--15b5KBX"
   },
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"協調器類別，用於統一模型訓練、評估和預測的流程。\"\"\"\n",
    "\n",
    "    def __init__(self, n_splits: int = Config.N_SPLITS, random_state: int = Config.RANDOM_STATE):\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "        if not self.logger.handlers:\n",
    "            logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    def run_experiment_tune(self,\n",
    "                       train_df: pd.DataFrame,\n",
    "                       test_df: pd.DataFrame,\n",
    "                       feature_engineering_pipeline: Callable,\n",
    "                       models: dict, # 使用 dict\n",
    "                       target_col: str = Config.TARGET_COL,\n",
    "                       tune_hyperparams: bool = False,\n",
    "                       tune_model_name: str = 'XGBoost', # 預設為 XGBoost\n",
    "                       n_trials: int = 50) -> tuple[pd.DataFrame, dict, pd.DataFrame, plt.Figure]: # 使用 tuple 和 dict\n",
    "        \"\"\"\n",
    "        啟動完整的實驗週期，可選配超參數調優。\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"--- 啟動新實驗 (特徵工程 FE: {feature_engineering_pipeline.__name__}) ---\")\n",
    "        if tune_hyperparams:\n",
    "            self.logger.info(f\"!!! 已為模型 '{tune_model_name}' 啟用超參數調優模式 !!!\")\n",
    "\n",
    "        test_ids = test_df['id'].copy()\n",
    "        original_train_for_analysis = train_df.copy()\n",
    "        y_train = train_df[target_col].astype(int)\n",
    "\n",
    "\n",
    "        self.logger.info(\"步驟 1: 應用特徵工程...\")\n",
    "        X_train_processed = feature_engineering_pipeline(train_df, is_train=True)\n",
    "        X_test_processed = feature_engineering_pipeline(test_df, is_train=False)\n",
    "\n",
    "\n",
    "        train_cols = X_train_processed.columns\n",
    "        test_cols = X_test_processed.columns\n",
    "        if not train_cols.equals(test_cols):\n",
    "            self.logger.warning(\"訓練集和測試集的欄位不一致! 正在對齊...\")\n",
    "            shared_cols = list(train_cols.intersection(test_cols))\n",
    "            X_train_processed = X_train_processed[shared_cols]\n",
    "            X_test_processed = X_test_processed[shared_cols]\n",
    "\n",
    "\n",
    "        models_to_train = models.copy()\n",
    "\n",
    "        if tune_hyperparams:\n",
    "            if tune_model_name not in models:\n",
    "                self.logger.error(\n",
    "                    f\"用於調優的模型 '{tune_model_name}' 未在 models 字典中找到。調優已取消。\")\n",
    "            else:\n",
    "                self.logger.info(f\"步驟 1.5: 為 '{tune_model_name}' 進行超參數調優...\")\n",
    "\n",
    "                cat_features = X_train_processed.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "\n",
    "                best_params = HyperparameterTuner.tune(\n",
    "                    X=X_train_processed,\n",
    "                    y=y_train,\n",
    "                    cat_feature_names=cat_features,\n",
    "                    n_trials=n_trials\n",
    "                )\n",
    "\n",
    "                # 確保 XGBoost 需要的固定參數被包含\n",
    "                best_params['random_state'] = self.random_state\n",
    "                best_params['verbose'] = 0\n",
    "                best_params['eval_metric'] = 'logloss'\n",
    "                best_params['n_jobs'] = -1\n",
    "                best_params['verbosity'] = 0\n",
    "\n",
    "                # 處理早停參數 (若 Optuna 未調優此參數，則使用預設值)\n",
    "                if 'early_stopping_rounds' not in best_params:\n",
    "                    best_params['early_stopping_rounds'] = 50\n",
    "\n",
    "                # 關鍵修正：實例化 XGBClassifier\n",
    "                # 由於我們現在只專注於 XGBoost，這裡假設 HyperparameterTuner.tune 返回的是 XGBoost 參數\n",
    "                tuned_model = XGBClassifier(**best_params)\n",
    "\n",
    "\n",
    "                tuned_model_name = f\"{tune_model_name}_Tuned\"\n",
    "                models_to_train = {tuned_model_name: tuned_model}\n",
    "                self.logger.info(f\"調優完成。模型 '{tuned_model_name}' 將用於訓練。\")\n",
    "\n",
    "        # 2. 訓練與評估模型\n",
    "        self.logger.info(\"步驟 2: 在交叉驗證上訓練模型...\")\n",
    "        all_results = self._evaluate_models(models_to_train, X_train_processed, y_train, X_test_processed)\n",
    "\n",
    "        # 3. 錯誤分析(暫時不用，因此需要修正)\n",
    "        # self.logger.info(\"步驟 3: 分析最佳模型的錯誤...\")\n",
    "        # best_model_name, error_df, dashboard_figure = ErrorAnalyzer.analyze_best_model(\n",
    "        #     all_results, y_train, original_train_for_analysis\n",
    "        # )\n",
    "# =========================================================================\n",
    "        # 修正開始\n",
    "        # =========================================================================\n",
    "        # 步驟 3: 確定最佳模型名稱並定義返回值 (取代 ErrorAnalyzer)\n",
    "        # 由於 run_experiment_tune 通常只訓練一個模型，我們直接取其名稱\n",
    "        best_model_name = list(all_results.keys())[0]\n",
    "        self.logger.info(f\"步驟 3: 最佳模型名稱確定為: {best_model_name}\")\n",
    "\n",
    "        # 錯誤分析已註解，必須定義返回變數作為預留位置\n",
    "        error_df = pd.DataFrame()\n",
    "        dashboard_figure = plt.figure()\n",
    "        # =========================================================================\n",
    "        # 修正結束\n",
    "        # =========================================================================\n",
    "        # 4. 生成提交文件\n",
    "        self.logger.info(\"步驟 4: 生成提交文件...\")\n",
    "        submission_df = self._generate_submission(\n",
    "            f\"submission_{best_model_name}_{feature_engineering_pipeline.__name__}.csv\",\n",
    "            test_ids,\n",
    "            all_results[best_model_name]['test_preds']\n",
    "        )\n",
    "\n",
    "        self.logger.info(\"--- 調優成功完成 ---\")\n",
    "        return submission_df, all_results, error_df, dashboard_figure\n",
    "\n",
    "    def run_experiment(self,\n",
    "                       train_df: pd.DataFrame,\n",
    "                       test_df: pd.DataFrame,\n",
    "                       feature_engineering_pipeline: Callable,\n",
    "                       models: dict, # 使用 dict\n",
    "                       target_col: str = Config.TARGET_COL) -> tuple[pd.DataFrame, dict, pd.DataFrame, plt.Figure]: # 使用 tuple 和 dict\n",
    "        \"\"\"\n",
    "        啟動完整的實驗週期：特徵工程 (FE)、訓練、錯誤分析、生成提交文件。\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"--- 啟動新實驗 (特徵工程 FE: {feature_engineering_pipeline.__name__}) ---\")\n",
    "\n",
    "        test_ids = test_df['id'].copy()\n",
    "        original_train_for_analysis = train_df.copy()\n",
    "        y_train = train_df[target_col].astype(int)\n",
    "\n",
    "        # 1. 特徵工程\n",
    "        self.logger.info(\"步驟 1: 應用特徵工程...\")\n",
    "        X_train_processed = feature_engineering_pipeline(train_df, is_train=True)\n",
    "        X_test_processed = feature_engineering_pipeline(test_df, is_train=False)\n",
    "\n",
    "        train_cols = X_train_processed.columns\n",
    "        test_cols = X_test_processed.columns\n",
    "        if not train_cols.equals(test_cols):\n",
    "            self.logger.warning(\"訓練集和測試集的欄位不一致! 正在對齊...\")\n",
    "            shared_cols = list(train_cols.intersection(test_cols))\n",
    "            X_train_processed = X_train_processed[shared_cols]\n",
    "            X_test_processed = X_test_processed[shared_cols]\n",
    "\n",
    "        # 2. 訓練與評估模型\n",
    "        self.logger.info(\"步驟 2: 在交叉驗證上訓練模型...\")\n",
    "        all_results = self._evaluate_models(models, X_train_processed, y_train, X_test_processed)\n",
    "\n",
    "        # 3. 錯誤分析(暫時不用，因此要修正)\n",
    "        # self.logger.info(\"步驟 3: 分析最佳模型的錯誤...\")\n",
    "        # best_model_name, error_df, dashboard_figure = ErrorAnalyzer.analyze_best_model(\n",
    "        #     all_results, y_train, original_train_for_analysis\n",
    "        # )\n",
    "# =========================================================================\n",
    "        # 修正開始\n",
    "        # =========================================================================\n",
    "        # 步驟 3: 確定最佳模型名稱並定義返回值 (取代 ErrorAnalyzer)\n",
    "        self.logger.info(\"步驟 3: 確定性能最佳的模型名稱...\")\n",
    "        # 根據 CV ROC AUC 平均值選出最佳模型\n",
    "        best_roc_auc = -1.0\n",
    "        best_model_name = None\n",
    "        for name, result in all_results.items():\n",
    "            current_auc = result['metrics_df']['ROC AUC'].mean()\n",
    "            if current_auc > best_roc_auc:\n",
    "                best_roc_auc = current_auc\n",
    "                best_model_name = name\n",
    "\n",
    "        # 錯誤分析已註解，必須定義返回變數作為預留位置\n",
    "        error_df = pd.DataFrame()\n",
    "        dashboard_figure = plt.figure()\n",
    "        # =========================================================================\n",
    "        # 修正結束\n",
    "        # =========================================================================\n",
    "        # 4. 生成提交文件\n",
    "        self.logger.info(\"步驟 4: 生成提交文件...\")\n",
    "        submission_df = self._generate_submission(\n",
    "            f\"submission_{best_model_name}_{feature_engineering_pipeline.__name__}.csv\",\n",
    "            test_ids,\n",
    "            all_results[best_model_name]['test_preds']\n",
    "        )\n",
    "\n",
    "        self.logger.info(\"--- 實驗成功完成 ---\")\n",
    "        return submission_df, all_results, error_df, dashboard_figure\n",
    "\n",
    "\n",
    "    def _evaluate_models(self, models: dict, X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame) -> dict: # 使用 dict\n",
    "        \"\"\"\n",
    "        使用交叉驗證訓練和驗證模型 (僅保留 XGBoost 相關邏輯)。\n",
    "        \"\"\"\n",
    "        self.logger.info(\"啟動交叉驗證...\")\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        results = {}\n",
    "\n",
    "        # 即使只用 XGBoost，偵測類別特徵仍是重要的步驟\n",
    "        cat_feature_names = X_train.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "        if cat_feature_names:\n",
    "            self.logger.info(f\"偵測到類別特徵: {cat_feature_names}\")\n",
    "\n",
    "        for name, model in models.items():\n",
    "            self.logger.info(f\"正在訓練模型: {name}\")\n",
    "            oof_preds = np.zeros(len(X_train))\n",
    "            test_preds_folds, fold_metrics_list, importances_folds = [], [], []\n",
    "\n",
    "\n",
    "            # 進行 K 折交叉驗證\n",
    "            for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                current_model = clone(model)\n",
    "                fit_params = {}\n",
    "\n",
    "                X_tr_fit, X_val_fit = X_tr, X_val\n",
    "\n",
    "                # --- 簡化後的模型特定邏輯：僅保留 XGBClassifier ---\n",
    "                if isinstance(current_model, XGBClassifier):\n",
    "                    fit_params['eval_set'] = [(X_val_fit, y_val)]\n",
    "                    fit_params['verbose'] = False # 設置 XGBoost 靜默模式\n",
    "\n",
    "                # 提醒：若 models 字典中包含非 XGBClassifier 模型，它們將在這裡使用預設 fit 參數訓練\n",
    "                # 且若為非原生支持類別特徵的模型，且數據中包含類別特徵，將會訓練失敗。\n",
    "                # ----------------------------------------------------\n",
    "\n",
    "                # 訓練模型\n",
    "                current_model.fit(X_tr_fit, y_tr, **fit_params)\n",
    "\n",
    "                # 預測\n",
    "                X_test_predict = X_test.copy()\n",
    "                # 由於只保留 XGBoost，且假設 XGBoost 透過 enable_categorical=True 原生處理類別特徵，\n",
    "                # 我們移除手動編碼邏輯。\n",
    "\n",
    "                proba_val = current_model.predict_proba(X_val_fit)[:, 1] # 驗證集預測概率\n",
    "                proba_test = current_model.predict_proba(X_test_predict)[:, 1] # 測試集預測概率\n",
    "\n",
    "                oof_preds[val_idx] = proba_val\n",
    "                test_preds_folds.append(proba_test)\n",
    "\n",
    "                # 收集指標和特徵重要性\n",
    "                fold_metrics_list.append(\n",
    "                    {'ROC AUC': roc_auc_score(y_val, proba_val), 'PR AUC': average_precision_score(y_val, proba_val)})\n",
    "                if hasattr(current_model, 'feature_importances_'):\n",
    "                    importances_folds.append(current_model.feature_importances_) # 樹模型\n",
    "                elif hasattr(current_model, 'coef_'):\n",
    "                    importances_folds.append(np.abs(current_model.coef_[0])) # 線性模型\n",
    "\n",
    "            # 儲存結果\n",
    "            results[name] = {\n",
    "                'oof_preds': oof_preds,\n",
    "                'test_preds': np.mean(test_preds_folds, axis=0),\n",
    "                'metrics_df': pd.DataFrame(fold_metrics_list),\n",
    "                'feature_importances': np.mean(importances_folds, axis=0) if importances_folds else None,\n",
    "                'feature_names': X_train.columns\n",
    "            }\n",
    "            self.logger.info(\n",
    "                f\"  模型 {name} | CV ROC AUC: {results[name]['metrics_df']['ROC AUC'].mean():.4f} ± {results[name]['metrics_df']['ROC AUC'].std():.4f}\")\n",
    "        return results\n",
    "\n",
    "    def _generate_submission(self, filename: str, df_test_id: pd.Series, test_preds: np.ndarray) -> pd.DataFrame:\n",
    "        print(f'filename = {filename}')\n",
    "        # 保留這個特殊的文件名處理邏輯\n",
    "        if filename == 'submission_CatBoost_final_run_v3_preprocessing.csv':\n",
    "            filename = 'submission.csv'\n",
    "        print(f'filename1 = {filename}')\n",
    "        submission_df = pd.DataFrame({'id': df_test_id, 'Exited': test_preds})\n",
    "        submission_df.to_csv(filename, index=False)\n",
    "        self.logger.info(f\"提交文件成功保存: {filename}\")\n",
    "        return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764319120456,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "iyAO6qVp51vH"
   },
   "outputs": [],
   "source": [
    "trainer = ModelTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764319120457,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "gZbEW0md5VVm"
   },
   "outputs": [],
   "source": [
    "# 整合 Optuna 找到的最佳參數和固定的 XGBoost 參數\n",
    "final_best_params = {\n",
    "    # Optuna 最佳參數\n",
    "    'n_estimators': 2692,\n",
    "    'learning_rate': 0.05786197845936901,\n",
    "    'max_depth': 3,\n",
    "    'reg_lambda': 1.0628185137032307e-08,\n",
    "    'reg_alpha': 3.255737505871401,\n",
    "    'subsample': 0.8409191153520594,\n",
    "    'colsample_bytree': 0.7834673458794292,\n",
    "\n",
    "    # 固定的參數 (修正 ValueError 的關鍵，尤其是 enable_categorical)\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'logloss',\n",
    "    'n_jobs': -1,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'enable_categorical': True, # 確保類別特徵能夠被正確處理\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# 實例化最終模型\n",
    "final_tuned_model = XGBClassifier(**final_best_params)\n",
    "\n",
    "# 創建包含最終模型的字典\n",
    "models_final = {\n",
    "    'XGBoost_Final_Tuned': final_tuned_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 25888,
     "status": "ok",
     "timestamp": 1764319146344,
     "user": {
      "displayName": "羅郁凱",
      "userId": "07548225885948904476"
     },
     "user_tz": -480
    },
    "id": "mOK2Th1W5W0O",
    "outputId": "1cb1eb88-df57-43e2-89fb-4c8d09326094"
   },
   "outputs": [],
   "source": [
    "best_fe_pipeline = FeatureEngineer.run_v2_preprocessing\n",
    "\n",
    "submission_final, results_final, errors_final, dashboard_final= trainer.run_experiment(\n",
    "    train_df=df_train,\n",
    "    test_df=df_test,\n",
    "    feature_engineering_pipeline=best_fe_pipeline,\n",
    "    models=models_final\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 假設您的最終模型變數名稱是 final_tuned_model\n",
    "# 如果您的 FeatureEngineer 有做特殊的特徵工程，建議連同 pipeline 一起儲存\n",
    "# 這裡示範儲存模型本身\n",
    "joblib.dump(final_tuned_model, 'churn_model_bank.pkl')\n",
    "\n",
    "print(\"模型已儲存為 churn_model_bank.pkl\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
